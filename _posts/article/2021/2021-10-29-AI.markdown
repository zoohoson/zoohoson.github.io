---
layout: post
title: '"AI 윤리" 선택 아닌 필수로…카카오·네이버도 만들었다'
subtitle: '211029금 AI윤리'
categories: doc
tags: article
comments: true
---

[링크](https://news.mt.co.kr/mtview.php?no=2021102716231924877)

"사회 책임감 있는 회사가 되도록 노력하겠다."   

김범수 카카오 이사회 의장은 지난 21일 국회 과학기술정보방송통신위원회의 방송통신위원회 국정감사에서 AI(인공지능) 알고리즘의 파급력을 우려하는 질문에 이같이 답했다.   

최근 사회 곳곳에서 벌어지는 AI 갈등의 중심에는 플랫폼 기업이 있다. 플랫폼 기업은 다양한 이해관계자를 연결하다 보니 '연결의 법칙'에 해당하는 알고리즘을 두고 각자의 입장에서 불만이 나오는 형국이다.   

이날 양대 플랫폼의 수장인 김 의장과 이해진 네이버 GIO(글로벌투자책임자)은 알고리즘에 대한 고민을 드러냈다. 설계 과정에서는 단순했던 요소들이 AI의 학습 과정을 거치며 복잡한 결과물로 재탄생하기 때문이다.   

이 GIO는 <span style="color:blue">"전 세계적으로 커다란 숙제이며 아무도 답을 알지 못하고, 찾아가는 과정 속에 있다"고 말했다. 처음부터 완벽한 AI와 알고리즘은 없으며, 일부에서 우려하는 알고리즘으로 인한 불평등 구조를 해결하기 위한 자체적인 노력을 하고 있다는 설명</span>이다.   

이와 관련해 네이버는 올해 2월 서울대와 협업해 만든 '네이버 AI 윤리 준칙'을 공개하기도 했다. 2018년부터 서울대 AI 정책 이니셔티브와 협력한 결과물로 네이버의 모든 구성원이 AI 개발과 이용에 있어 지켜야 할 원칙을 담았다.   

윤리 준칙은 △사람을 위한 AI 개발 △다양성의 존중 △합리적인 설명과 편리성의 조화 △안전을 고려한 서비스 설계 △프라이버시 보호와 정보 보안 총 5개 조항으로 구성돼 있다. 알고리즘으로 인한 모든 불만을 불식할 수는 없어도 기본적으로 지켜야 할 대원칙을 담은 셈이다.   

카카오 역시 국내 기업으로는 최초로 2018년 알고리즘 윤리 헌장을 제정한 것은 물론 지난 2월 전 직원을 대상으로 AI 윤리 교육을 시행했다. 각 직원들이 각자 업무에서 AI윤리를 어떻게 준수해야 할지, 디지털 책임을 어떻게 구현할지 등의 내용으로 진행됐다.   

<span style="color:blue">업계에서는 이제 AI 윤리가 단순히 사회 공헌 차원에 그치지 않는다고 지적한다. 기술의 불확실성이 커진 만큼 AI 윤리가 사업의 흥망성쇄를 가를수 있다는 것이다. 각종 혐오 발언을 막지 못했던 '이루다 사태'는 물론 최근 페이스북의 내부고발 사태도 알고리즘과 무관치않다. 구글이 상반기 AI 윤리 담당 연구원을 기존 200명에서 400명까지 늘린 것도 이 같은 흐름을 반증</span>한다.   

세계 각국에서도 AI 윤리를 두고 다양한 고민이 나온다. 유럽연합(EU)에서는 AI로 발생할 수 있는 위험을 '용납할 수 없는 위험', '높은 위험', '낮은 위험', '최소한도 위험' 등 단계별로 분류하고 합당한 규제를 법으로 만들 것을 제안하기도 했다.   

이런 가운데 한국지능정보사회진흥원(NIA)은 지난달 '국가 AI 사업추진 윤리원칙'을 제정했다. 그간 공적 차원에서 AI 기반의 제품 및 서비스를 기획·개발·상용화할 때 활용 가능한 원칙이 존재하지 않던 상황이다. AI 윤리에 대한 고민이 부족한 중소·영세 업체 등 민간에서도 활용 가능한 가이드라인이 될 전망이다.   

NIA가 제시한 윤리원칙은 '사람과 책임', '안전과 평등', '공익과 민주사회'라는 3가치 핵심가치와 9가지 윤리원칙으로 구성된다. 이와 관련 문용식 NIA 원장은 "인공지능 기술이 선한 영향력을 발휘하여 국가와 국민에게 이롭게 쓰일 수 있도록 더욱 노력하겠다"고 말했다.   

머니투데이   
이동우 기자   
* * *

### 2. 키워드 : \#인공지능 \#윤리
### 3. 요약 : 인공지능 윤리, 선택이 아닌 필수로.
### 4. 궁금한 점 : 최근(2021년) 공기업 논술시험을 보면, 인공지능 윤리문제가 빠지지 않는다. 잘못된 판단을 하는 이유와 해결책을 항상 묻는다. 앞으로 인공지능 윤리가 점점 더 문제가 되고, XAI와 알고리즘을 아는 법률전문가 분야가 이슈가 될 것같다. 네이버의 이 GIO도 아직 아무도 답을 알지못한다고 답했는데, 어떻게 찾아가고 있는지 궁금하다.
