---
layout: post
title: '"개발단계부터 AI에 윤리의식 입혀야"'
subtitle: '211202목 윤리AI'
categories: doc
tags: article
comments: true
---

[링크](https://news.naver.com/main/read.naver?mode=LPOD&mid=sec&oid=015&aid=0004635879)
21.12.02. 한국경제 서민준 기자   

AI미래포럼 웨비나   

신뢰할 수 있는 AI 구현 위해   
모든 과정에서 '영향평가' 필요   

"데이터 편향 등 법적 문제 존재   
개인정보 보호 방안도 마련해야"   

올해 초 ‘이루다’라는 인공지능(AI) 챗봇이 서비스 이용자와의 대화에서 장애인·성소수자 등에 대한 혐오 발언을 쏟아내 논란을 일으켰다. <span style="color:blue">이루다는 개인정보 유출 논란까지 겹쳐 서비스가 중단</span>됐다. 이 사건은 “AI를 믿을 수 있는 거냐”는 회의론을 불러오는 등 AI업계 전반에 타격을 줬다.   

이런 불의의 사고를 예방하려면 AI 개발 전 과정에서 법적·윤리적 위험을 낮추는 체계를 구축하는 데 힘을 쏟아야 한다는 주장이 제기됐다. 이른바 ‘신뢰할 수 있는 AI(Trustworthy AI)’를 구현해야 한다는 얘기다.   

“AI 신뢰도 제고에 힘 모아야”
로베르토 지카리 독일 괴테 프랑크푸르트대 교수는 지난 1일 열린 ‘AI미래포럼(AIFF) 웨비나’에서 “산업계와 학계, 정책 입안자 등이 함께 힘을 모아 신뢰할 수 있는 AI를 구현하기 위한 체계를 만들어야 한다”고 말했다. 이번 웨비나는 ‘신뢰 가능한 AI’를 주제로 국내 최대 AI 연구 네트워크인 AI미래포럼과 한국과학기술단체총연합회, 재유럽한인과학기술자협회가 함께 주최했다.   

지카리 교수는 약 30년간 빅데이터와 AI를 연구해온 세계적인 데이터 과학자다. 그는 “세계적으로 AI의 잠재적 위험을 낮춰야 한다는 논의가 활발하다”며 유럽연합(EU) 사례를 소개했다.   

EU 집행위원회는 2019년 <span style="color:blue">‘신뢰할 수 있는 AI를 위한 프레임워크’를 발표했다. 여기서 △인간의 자율성 존중 △무해성 △공정성 △설명 가능성 등 네 가지 원칙과 기술적 안전성, 개인정보 보호 등 AI에 요구되는 일곱 가지 사항을 정했다. EU는 이런 내용을 바탕으로 AI 제품·서비스를 규제하는 방향의 입법까지 추진</span>하고 있다.   

지카리 교수는 “EU의 AI 규제는 기준이 모호하다는 한계가 있지만 AI의 위험도를 낮추는 시도 자체는 타당하다”고 강조했다. 이어 “AI 알고리즘을 설계하고 개발하는 단계부터 서비스·제품을 만들어 배포하고 모니터링하는 단계까지 전 과정에 걸쳐 AI의 법적·기술적·윤리적 영향을 평가하는 체계를 만들어야 한다”고 했다.

“데이터 편향 예방 노력 중요”   

<span style="color:blue">허성욱 서울대 법학전문대학원 교수는 “민간에선 데이터와 AI를 기반으로 의사결정을 내리는 기업이 많이 나오고 있고, 머지않아 정부 정책도 그렇게 될 가능성이 크다”고 말했다. 그는 “AI가 내리는 결정을 어떻게 검증할지, 결정 과정을 얼마나 투명하게 공개할지, 잘못된 결정이 나오면 책임 소재를 어떻게 할지 등 법적인 문제를 지금부터 고민할 필요가 있다”</span>고 했다.   

AI의 위험도를 낮추기 위한 구체적인 대안도 제시됐다. AI 스타트업 노타의 김태호 최고기술책임자(CTO)는 “AI 기업 입장에선 개인정보 보호가 가장 큰 과제 중 하나”라며 <span style="color:blue">“데이터를 클라우드가 아니라 스마트폰·CCTV(폐쇄회로TV) 등 ‘에지’ 단계에서 처리하면 정보 유출 위험을 줄일 수 있다”</span>고 말했다. AI업계에서 에지란 데이터가 생성되는 스마트 기기 혹은 그와 가까운 지점을 뜻한다. 김 CTO는 “노타는 에지 단계에서 데이터 처리를 최적화하는 기술을 집중 개발하고 있다”고 소개했다.   

이광희 보잉한국기술연구소 AI 리드는 “편향된 데이터로 AI를 학습시키면 신뢰도에 치명적”이라며 “데이터 편향을 예방할 수 있게 사전 체크해야 할 항목을 체계화할 필요가 있다”고 말했다.   

* * *

### 2. 키워드 : \#윤리AI
### 3. 요약 : AI 신뢰도 점점 중요해
### 4. 궁금한 점 : 에지에서 처리한다는것이 federated learning 을 의미하는걸까. 
